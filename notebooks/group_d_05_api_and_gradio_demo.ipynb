{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f3a258",
   "metadata": {},
   "source": [
    "# group_d_05_api_and_gradio_demo.ipynb\n",
    "\n",
    "This notebook loads the fine-tuned DistilBERT ticket classifier from `models/distilbert-ticket-classifier/`, defines an inference function that returns predicted label and confidence, and launches an interactive Gradio demo directly in the notebook (`share=True`).\n",
    "\n",
    "The notebook is organized into sequential code blocks with comments explaining each line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages in the notebook environment if they not already installed.\n",
    "try:\n",
    "    import gradio as gr  # noqa: F401\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification  # noqa: F401\n",
    "except Exception:\n",
    "    # Install transformers, gradio and torch if missing.\n",
    "    %pip install -q transformers[torch] gradio torch --upgrade\n",
    "    import gradio as gr  # noqa: F401\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification  # noqa: F401\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc12997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b86b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required for inference and display\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Transformers components for loading tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax  # to convert logits to probabilities\n",
    "\n",
    "# Gradio for the interactive demo\n",
    "import gradio as gr\n",
    "\n",
    "# Determine whether a CUDA GPU is available and set the device accordingly.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e32629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the fine-tuned DistilBERT model directory\n",
    "MODEL_DIR = Path(\"../models/distilbert-ticket-classifier\")\n",
    "\n",
    "# Define the label names in the same order the model was trained with.\n",
    "LABELS = ['other', 'technical', 'account', 'billing']\n",
    "\n",
    "# Basic checks to help user debug common issues.\n",
    "if not MODEL_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Model directory not found at: {MODEL_DIR.resolve()}. Please ensure the path is correct.\")\n",
    "\n",
    "print(\"Model directory found:\", MODEL_DIR.resolve())\n",
    "print(\"Labels:\", LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model from the model directory.\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(MODEL_DIR))\n",
    "\n",
    "# Load model weights. Use local files in MODEL_DIR.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR))\n",
    "# Move model to the selected device (GPU if available, otherwise CPU)\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode (disables dropout, etc.)\n",
    "\n",
    "# Print model summary: number of labels and device placement.\n",
    "try:\n",
    "    num_labels = model.config.num_labels\n",
    "except Exception:\n",
    "    num_labels = None\n",
    "print(f\"Loaded model with num_labels={num_labels} and device={device}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prediction function that accepts a text string and returns a label and confidence score.\n",
    "def predict_ticket_label(text, top_k=1):\n",
    "    \"\"\"Predict label(s) for a single input text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input ticket or customer message.\n",
    "        top_k (int): Number of top labels to return (default 1).\n",
    "    \n",
    "    Returns:\n",
    "        If top_k == 1: (label: str, confidence: float)\n",
    "        If top_k > 1: list of tuples [(label, confidence), ...]\n",
    "    \"\"\"\n",
    "    # Tokenize the input text. return_tensors='pt' returns PyTorch tensors.\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # Move tensors to the same device as the model (GPU/CPU).\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Disable gradient computation for inference to save memory and computation time.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # The model outputs logits for each class in outputs.logits\n",
    "        logits = outputs.logits.cpu().numpy()[0]\n",
    "    \n",
    "    # Convert logits to probabilities using softmax for interpretability.\n",
    "    probs = softmax(logits)\n",
    "    \n",
    "    # Get indices of top_k predictions sorted by probability descending.\n",
    "    top_indices = probs.argsort()[::-1][:top_k]\n",
    "    \n",
    "    # Build results as (label, confidence) pairs.\n",
    "    results = [(LABELS[idx], float(probs[idx])) for idx in top_indices]\n",
    "    \n",
    "    if top_k == 1:\n",
    "        return results[0]  # return (label, confidence)\n",
    "    return results  # return list of (label, confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check on the prediction function with example texts.\n",
    "examples = [\n",
    "    \"My internet connection is down and I cannot access my email.\",\n",
    "    \"I was charged twice on my last invoice. Please help.\",\n",
    "    \"How do I change my account password?\",\n",
    "    \"I want to update my billing information.\",\n",
    "    \"This is an unrelated question not covered by categories.\"\n",
    "]\n",
    "\n",
    "for ex in examples:\n",
    "    label, conf = predict_ticket_label(ex)\n",
    "    print(f\"Input: {ex}\\nPredicted label: {label}, confidence: {conf:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12491e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wrapper function compatible with Gradio that returns a human-friendly output.\n",
    "def gradio_predict(text):\n",
    "    \"\"\"Gradio wrapper that returns a formatted string with predicted label and confidence.\"\"\"\n",
    "    label, conf = predict_ticket_label(text)\n",
    "    # Format confidence as percentage with two decimals\n",
    "    return f\"Label: {label} | Confidence: {conf*100:.2f}%\"\n",
    "\n",
    "# Build the Gradio interface components:\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_predict,  # function to call\n",
    "    inputs=gr.Textbox(lines=2, placeholder='Enter customer support message here...'),  # text input box\n",
    "    outputs=gr.Textbox(label='Prediction'),  # text output box\n",
    "    title='DistilBERT Ticket Classifier Demo',  # UI title\n",
    "    description='Enter a customer support message and see predicted category and confidence.'  # short description\n",
    ")\n",
    "\n",
    "# Launch the Gradio demo in the notebook and create a public share link.\n",
    "iface.launch(share=True, inline=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4933f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title=\"Ticket Classifier API\")\n",
    "\n",
    "class TicketRequest(BaseModel):\n",
    "    text: str\n",
    "    top_k: int = 1\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict_ticket(request: TicketRequest):\n",
    "\n",
    "    \"\"\"API endpoint to predict ticket label(s) for input text.\n",
    "    \n",
    "    Args:\n",
    "        request (TicketRequest): Input request with text and top_k.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results with labels and confidences.\n",
    "    \"\"\"\n",
    "    results = predict_ticket_label(request.text, top_k=request.top_k)\n",
    "    if request.top_k == 1:\n",
    "        label, confidence = results\n",
    "        return {\"label\": label, \"confidence\": round(confidence, 4)}\n",
    "    else:\n",
    "        return [{\"label\": label, \"confidence\": round(conf, 4)} for label, conf in results]\n",
    "\n",
    "# To run API server manually (commented out to avoid blocking notebook):    \n",
    "#if __name__ == \"__main__\": \n",
    "#    uvicorn.run(app, host=\"0.0.0.0\", port=8000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58372cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Gradio interface to display Top-3 predictions in a table format.\n",
    "\n",
    "def gradio_predict_topk(text):\n",
    "    \"\"\"Return top-3 predictions with confidence for Gradio visualization.\"\"\"\n",
    "    results = predict_ticket_label(text, top_k=3)\n",
    "    output = {label: f\"{conf*100:.2f}%\" for label, conf in results}\n",
    "    return output\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_predict_topk,\n",
    "    inputs=gr.Textbox(lines=3, placeholder=\"Enter customer message here...\"),\n",
    "    outputs=gr.Label(label=\"Top Predictions (Confidence %)\"),\n",
    "    title=\"DistilBERT Ticket Classifier Demo (Enhanced)\",\n",
    "    description=\"Displays top-3 predicted categories and confidence scores.\",\n",
    ")\n",
    "\n",
    "iface.launch(share=True, inline=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
