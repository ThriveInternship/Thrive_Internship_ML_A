{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b94ed565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69bc0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/customer_support_tickets_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab29cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 396\n",
      "Test set size: 99\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text_cleaned'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "print(f'Training set size: {X_train.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b381f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Performance:\n",
      "Accuracy: 0.26262626262626265\n",
      "F1 Score: 0.10925252525252524\n",
      "Confusion Matrix:\n",
      "[[ 0  0 24  0]\n",
      " [ 0  0 24  0]\n",
      " [ 0  0 26  0]\n",
      " [ 0  0 25  0]]\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent') # Using most frequent class strategy by initialization Majority Classifier\n",
    "\n",
    "dummy.fit(X_train, y_train) # fit the model\n",
    "\n",
    "y_pred = dummy.predict(X_test) # make predictions\n",
    "\n",
    "print(\"Dummy Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1d64ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + vectorizer + Logistic Regression model trained.\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.9494949494949495\n",
      "F1 Score: 0.9499376443752823\n",
      "Confusion Matrix:\n",
      " [[20  4  0  0]\n",
      " [ 0 24  0  0]\n",
      " [ 0  0 26  0]\n",
      " [ 0  1  0 24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     account       1.00      0.83      0.91        24\n",
      "     billing       0.83      1.00      0.91        24\n",
      "       other       1.00      1.00      1.00        26\n",
      "   technical       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.96      0.95      0.95        99\n",
      "weighted avg       0.96      0.95      0.95        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english') # Create TF-IDF vectorizer to vectorize text data\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000) # Initialize Logistic Regression model training\n",
    "lr.fit(X_train_vec, y_train) # Fit the model to the training data\n",
    "\n",
    "y_pred_lr = lr.predict(X_test_vec) # Make predictions on the test data\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\"TF-IDF + vectorizer + Logistic Regression model trained.\")\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(f\"Accuracy: {acc_lr}\")\n",
    "print(f\"F1 Score: {f1_lr}\")\n",
    "print(f\"Confusion Matrix:\\n {cm_lr}\")\n",
    "\n",
    "print(f\"Classification Report:\\n {classification_report(y_test, y_pred_lr)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "623348cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model Comparison:\n",
      "                 Model  Accuracy  F1 Score\n",
      "0     Dummy Classifier  0.262626  0.109253\n",
      "1  Logistic Regression  0.949495  0.949938\n"
     ]
    }
   ],
   "source": [
    "baseline_results = pd.DataFrame({\n",
    "    'Model': ['Dummy Classifier', 'Logistic Regression'],\n",
    "    'Accuracy': [accuracy_score(y_test, y_pred), accuracy_score(y_test, y_pred_lr)],\n",
    "    'F1 Score': [f1_score(y_test, y_pred, average='weighted'), f1_score(y_test, y_pred_lr, average='weighted')]\n",
    "})\n",
    "print(\"\\nBaseline Model Comparison:\")\n",
    "print(baseline_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5862731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model metrics saved to '../src/baseline_model_metrics.json'\n"
     ]
    }
   ],
   "source": [
    "#saving metrics to json file\n",
    "#preparing metrics dictionary\n",
    "metrics = {\n",
    "    'Dummy Classifier': {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n",
    "    },\n",
    "    'tfidf + logreg': {\n",
    "        'Accuracy': acc_lr,\n",
    "        'F1 Score': f1_lr,\n",
    "        'confusion_matrix': cm_lr.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../src/baseline_model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "    print(\"Baseline model metrics saved to '../src/baseline_model_metrics.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "119d7bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     account       1.00      0.83      0.91        24\n",
      "     billing       0.83      1.00      0.91        24\n",
      "       other       1.00      1.00      1.00        26\n",
      "   technical       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.96      0.95      0.95        99\n",
      "weighted avg       0.96      0.95      0.95        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_lr)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
